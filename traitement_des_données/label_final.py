import pandas as pd

# Charger les donn√©es
df = pd.read_csv(r"C:\Users\pret\IF29-Twitter\dataset\cleaned_data_all.csv")

# Remplacer les valeurs manquantes (essentiel pour ratio)
df["follower_friend_ratio"] = df["follower_friend_ratio"].fillna(0)

# -------- Crit√®res fond√©s sur litt√©rature SPOT, Botometer, Twitter API -------- #

# 1. follower_friend_ratio trop bas : typique d'un bot qui suit en masse mais peu suivi
critere_ratio = df["follower_friend_ratio"] < 0.1

# 2. active_hours tr√®s court (compte qui ne dure que quelques heures)
critere_duree_active = df["active_hours"] < 24  # moins d'un jour d'activit√©

# 3. tweets_per_day tr√®s √©lev√© (activit√© automatis√©e)
critere_frequence = df["tweets_per_day"] > 50

# 4. aggressiveness anormale (hyperactivit√© combin√©e tweets + follows)
critere_aggressivite = df["aggressiveness"] > 1

# 5. visibilit√© tr√®s √©lev√©e (usage abusif de hashtags/mentions)
critere_visibilite = df["visibility"] > 5

# -------- Attribution du label -------- #
# Si l'utilisateur satisfait √† au moins un de ces crit√®res, on le consid√®re suspect
df["label"] = (
    critere_ratio |
    critere_duree_active |
    critere_frequence |
    critere_aggressivite |
    critere_visibilite
).astype(int)

# -------- Export final -------- #
df.to_csv("cleaned_data_with_validated_label.csv", index=False)
print("‚úÖ Fichier export√© : cleaned_data_with_validated_label.csv")

# -------- Optionnel : R√©sum√© rapide -------- #
nb_total = len(df)
nb_suspects = df["label"].sum()
print(f"\nüìä R√©sum√© : {nb_suspects} profils suspects d√©tect√©s sur {nb_total} (soit {nb_suspects/nb_total:.2%})")
